{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Copyright 2024 Google LLC\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Djt2AE7sifF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YouTube AI Generated Live Stream: Colab\n",
        "\n",
        "Author: Guillaume Bentaieb <br />\n",
        "Instruction: this Notebook needs to be opened in Colab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YouTubeLabs/code-samples/blob/main/yt_ai_generated_live_stream/yt_ai_generated_live_stream.ipynb)"
      ],
      "metadata": {
        "id": "bNqEfax5zEC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Let's have some fun with AI and YouTube !\n",
        "\n",
        "## Objective\n",
        "**The goal of this Colab** is to create a live stream fully generated via AI. For that, we will use the [YouTube Data API](https://developers.google.com/youtube/v3) to pull every X seconds the lastest chat message posted by viewers on the live stream, send that as a prompt to [Vertex AI](https://cloud.google.com/vertex-ai) to generate an image via AI, and stream that image back to YouTube.\n",
        "\n",
        "It's probably easier to understand the concept with an example. If a user comments your live stream with: \"I want to see a cute dog wearing goggles\", we will get that comment and send it to Vertex AI. Vertex AI will generate an image of a cute dog wearing goggles, and we will display that image in the live stream. So basically, viewers are actually creating the content that they're watching.\n",
        "\n",
        "Want to see that in action ? [This is an example](https://www.youtube.com/watch?v=ZaI6FmWVGWE) of a YouTube live stream generated with this very Colab.\n",
        "\n",
        "Looks cool right? :)\n",
        "\n",
        "## Things to know before we start\n",
        "**Security:**\n",
        "- <ins>Moderation</ins>. Maybe the first thing that you're thinking right now is: what if the viewers ask for something inappropriate ? The algorithm used in this Colab will use Google's [Natural Language AI API](https://cloud.google.com/natural-language) to check the text against a list of safety attributes, which includes 'harmful categories' and topics that may be considered sensitive (learn more [here](https://cloud.google.com/natural-language/docs/moderating-text)). Additionally, you can learn more about YouTube Community Guidelines [here](https://www.youtube.com/howyoutubeworks/policies/community-guidelines/) and Vertex AI's safeguards [here](https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen?hl=en#safety-filters).\n",
        "\n",
        "- <ins>YouTube Live Stream</ins>: This script will never modify the visibility of your live stream, and your livestream must be unlisted for this Colab to work. Once the live stream starts, if you want to make the stream public, you will need to manually change the visibility from the YouTube Live Control Room.\n",
        "\n",
        "**Access:**\n",
        "- Make sure you do have access to the Vertex AI API [here](https://cloud.google.com/vertex-ai/docs/generative-ai/image/generate-images)\n",
        "- Make sure you have enabled live streaming on your YouTube channel. More info [here](https://support.google.com/youtube/answer/2474026)\n",
        "\n",
        "**Difficulty:**\n",
        "- This Colab requires a bit of set up as we will use many Google / YT features to make it work. Nothing to be afraid of, but please don't skip any steps and read the instruction thoroughly to make sure you can get this working !\n",
        "\n",
        "<br/>\n",
        "\n",
        "***\n",
        "\n",
        "<br/>\n",
        "\n",
        "Ready ? Let's go !!"
      ],
      "metadata": {
        "id": "CqKQ17G5zpvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0: Enable GPU resources for your Colab\n",
        "\n",
        "Before we begin: This Colab runs better with GPU resources available. For that, click on \"Runtime\" in Colab's menu (at the top of the page), and select \"change runtime type\". Keep Python as runtime type, select one of the available GPU hardware (e.g. T4 GPU), and click save. If no GPU hardware is available, then no worries, we'll run everything on CPU :)\n",
        "\n",
        "<br/>\n",
        "\n",
        "<sub>[Optional / PRO Tip] For even better performances, you can look into running this Colab on your local machine with CUDA compatible GPU</sub>"
      ],
      "metadata": {
        "id": "t8my-J1FdlqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Google Cloud Setup\n",
        "\n",
        "To use Vertex AI, Google Natural Language AI and the YouTube Data API, we need to create a Google Cloud Project, and set it up correctly.\n",
        "\n",
        "1. First, if it's your first time using Google Cloud, then [create a new free account](https://cloud.google.com/free) and claim your free credits, which will enable you to run this Colab free of charge for countless of hours !\n",
        "2. Then, create a [Google Cloud Project](https://developers.google.com/workspace/guides/create-project).\n",
        "3. When your project is created, you can then go to your [Google Cloud Project Dashboard](https://console.cloud.google.com/home), make sure the right project is selected (otherwise, use the top left dropdown menu to select your newly created project), then copy the ID of your project (Project ID), paste the value below and run the script (by clicking on the play icon that shows when you over the script):"
      ],
      "metadata": {
        "id": "D_pKXIqK4ROf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global PROJECT_ID\n",
        "PROJECT_ID = ''  # @param {type:\"string\"}\n",
        "\n",
        "print('Project_ID saved!')"
      ],
      "metadata": {
        "id": "XipZyH0X6i2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. If this is your first time using Google Cloud, then you don't need to activate billing as you can use your free credits. Otherwise, make sure billing is activated [here](https://console.cloud.google.com/billing) (For example, if you go live for 1h with this Colab, it'll cost you less than 5 dollars [last update: 2024-20-02, subject to variations], cf [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Google Natural Language pricing](https://cloud.google.com/natural-language/pricing), and the YouTube Data API is free of charge)\n",
        "\n",
        "5. Enable the following APIs for your project:\n",
        "- [Vertex AI API](https://console.cloud.google.com/marketplace/product/google/aiplatform.googleapis.com)\n",
        "- [Google Natural Language API](https://console.cloud.google.com/marketplace/product/google/language.googleapis.com)\n",
        "- [YouTube Data API](https://console.cloud.google.com/marketplace/product/google/youtube.googleapis.com)\n",
        "\n",
        "6. Create an API Key\n",
        "- [Go to the API Credentials page](https://console.cloud.google.com/apis/credentials)\n",
        "- Click on \"Create Credentials\" at the very top of the page, and click on \"API Key\"\n",
        "- Copy the API key once it's created, run the following script and follow the instructions (spoiler: it will ask you to paste your API key !):"
      ],
      "metadata": {
        "id": "eVwcZQO3-Qt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "global API_KEY\n",
        "API_KEY = getpass('Paste your API Key here, and hit enter:')\n",
        "\n",
        "print('API_KEY saved!')"
      ],
      "metadata": {
        "id": "oj5JFqjAPPoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Connect your Google Cloud Project to this Colab by running the 2 following scripts (please follow the given instructions for each script, and don't forget to hit the \"enter\" key after copy / pasting your authorization code :) ):"
      ],
      "metadata": {
        "id": "-I-HHyE4PP7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project $PROJECT_ID"
      ],
      "metadata": {
        "id": "pu5ltC4V1o86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login --scopes='https://www.googleapis.com/auth/cloud-platform'"
      ],
      "metadata": {
        "id": "juxjneCi2x26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Create Your YouTube Live Stream\n",
        "\n",
        "The entire goal of this project is to live stream on YouTube, so let's create a YouTube live stream !\n",
        "\n",
        "1. Go to [YouTube](https://www.youtube.com/) and then click the \"Create\" icon in the top right corner (next to your profile icon and the notification bell)\n",
        "2. Select \"Go Live\". This will redirect you to the YouTube Live Control Room\n",
        "3. In the live Control Room, click on the \"Manage\" tab on the left, then click on \"Schedule Stream\". Click on \"create new\" (if shown) and follow the instructions. Make sure that you set the following settings for your stream:\n",
        "    - Broadcast type = Streaming Software\n",
        "    - Audience = Not Made For Kids\n",
        "    - Altered content = Yes (more info [here](https://support.google.com/youtube/answer/14328491))\n",
        "    - Comments = on (with moderation = strict if possible)\n",
        "    - Who can send messages = anyone\n",
        "    - Visibility = unlisted\n",
        "    - Latency = low\n",
        "    - (the rest can be set as you please)\n",
        "4. When you're done setting up your stream, you should end up in the Live Control Room, and the URL of the page should look like this: `https://studio.youtube.com/video/XXXXXXXXXXX/livestreaming`. `XXXXXXXXXXX` is the ID of your newly created live stream. Copy it, paste it below and run the script:"
      ],
      "metadata": {
        "id": "zZsPd_O6uKwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global LIVE_STREAM_ID\n",
        "LIVE_STREAM_ID = ''  # @param {type:\"string\"}\n",
        "\n",
        "print('LIVE_STREAM_ID saved!')"
      ],
      "metadata": {
        "id": "pg1OWWz_0EjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Go back to the YouTube live Control Room (URL: `https://studio.youtube.com/video/XXXXXXXXXXX/livestreaming`, where `XXXXXXXXXXX` is the ID of your newly created live stream). In the \"Stream Settings\" section, you should be able to find your \"Stream key\" for your live stream. Copy its value, paste it below and run the script:"
      ],
      "metadata": {
        "id": "-q6JiaFcQF9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "global LIVE_STREAM_KEY\n",
        "LIVE_STREAM_KEY = getpass('Paste your Stream Key here, and hit enter:')\n",
        "\n",
        "print('LIVE_STREAM_KEY saved!')"
      ],
      "metadata": {
        "id": "Qx3j9qVwP96g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. In the YouTube Live Control Room, under \"Stream Settings\", make also sure that:\n",
        "- The parameter \"Enable auto-start\" is set to false\n",
        "- The parameter \"Enable DVR\" is set to false (DVR won't work well with this stream)"
      ],
      "metadata": {
        "id": "FkPc7nWSUWOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Python Script\n",
        "\n",
        "Let's install the python dependencies we need, and declare the functions we will use to create Gen AI images and live stream them on YouTube.\n",
        "\n",
        "1. Run the following script to install Python dependencies:"
      ],
      "metadata": {
        "id": "oXMNbnCw3aKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python==0.2.0"
      ],
      "metadata": {
        "id": "_d85tUVV3uxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run the following script to define our python functions:"
      ],
      "metadata": {
        "id": "1pourtMs4IIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT\n",
        "\n",
        "from vertexai.preview.vision_models import Image, ImageGenerationModel\n",
        "from string import ascii_letters\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from multiprocessing import Process\n",
        "from googleapiclient import discovery\n",
        "from google.cloud import language\n",
        "\n",
        "import google.auth\n",
        "import vertexai\n",
        "import textwrap\n",
        "import ffmpeg\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from matplotlib import colormaps\n",
        "\n",
        "################################################################################\n",
        "# Global Variables, Constants and Utils Functions\n",
        "################################################################################\n",
        "\n",
        "# VERTEX AI: location of physical computing resources\n",
        "VERTEX_AI_CLOUD_LOCATION = \"us-central1\"\n",
        "\n",
        "# YT DATA API: define api and scopes\n",
        "YT_API_SERVICE_NAME = \"youtube\"\n",
        "YT_API_VERSION = \"v3\"\n",
        "\n",
        "# YT DATA API: global variable to store YT API service. Set later during init.\n",
        "global YOUTUBE\n",
        "YOUTUBE = None\n",
        "\n",
        "# PATHs to store AI Generated Images and image animation\n",
        "TEMP_IMAGE_PATH = \"_temp_genimage.png\"\n",
        "IMAGE_PATH = \"genimage.png\"\n",
        "TEMP_ANIMATION_PATH = \"_temp_animation.mov\"\n",
        "ANIMATION_PATH = \"animation.mov\"\n",
        "\n",
        "# Image size in pixel\n",
        "IMAGE_SIZE = 1080\n",
        "\n",
        "# Minimum time to wait between 2 image generations\n",
        "MIN_IMAGE_AI_GEN_REFRESH_SECONDS = 20\n",
        "\n",
        "# Time of animation displayed on top of GEN AI image\n",
        "ANIMATION_TIME_SECONDS = 5\n",
        "\n",
        "# Fallback message to use if no live chat message can be found\n",
        "FALLBACK_LIVE_CHAT_AUTHOR = \"The universe\"\n",
        "FALLBACK_LIVE_CHAT_TEXT = \"A beautiful and empty void\"\n",
        "FALLBACK_LIVE_CHAT_MESSAGE = {\n",
        "    \"messageAuthor\": FALLBACK_LIVE_CHAT_AUTHOR,\n",
        "    \"messageText\": FALLBACK_LIVE_CHAT_TEXT,\n",
        "}\n",
        "\n",
        "# Live streams details fetched later during init\n",
        "global LIVE_CHAT_ID, LIVE_CHAT_PAGE_TOKEN\n",
        "LIVE_CHAT_ID = None  # YT Live Chat ID\n",
        "LIVE_CHAT_PAGE_TOKEN = None  # YT Chat Pagignation Token\n",
        "\n",
        "\n",
        "def truncate_string(string, width):\n",
        "    \"\"\"Utils function: truncate long strings\"\"\"\n",
        "    if len(string) > width:\n",
        "        string = string[: width - 3] + \"...\"\n",
        "    return string\n",
        "\n",
        "\n",
        "def run_in_parallel(*fns):\n",
        "    \"\"\"Utils function: Run multiple processes in parallel\"\"\"\n",
        "    proc = []\n",
        "    for fn in fns:\n",
        "        p = Process(target=fn)\n",
        "        p.start()\n",
        "        proc.append(p)\n",
        "    for p in proc:\n",
        "        p.join()\n",
        "\n",
        "\n",
        "def execute_youtube_api_call(api_method, **kwargs):\n",
        "    \"\"\"Utils function: Execute YT API endpoint and catch errors\"\"\"\n",
        "    result = None\n",
        "    print(\n",
        "        f\"Calling the YouTube API endpoint: {api_method.__name__}, \" +\n",
        "        \"with the following parameters: \",\n",
        "        kwargs)\n",
        "    try:\n",
        "        result = api_method(**kwargs).execute()\n",
        "        print(\n",
        "            f\"Called YouTube API endpoint {api_method.__name__} with success !\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\n",
        "            \"An error occured while calling the Youtube API endpoint: \" +\n",
        "            f\"{api_method.__name__}. Error:\",\n",
        "            e)\n",
        "\n",
        "    return result\n",
        "\n",
        "################################################################################\n",
        "# Functions\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def init_youtube_api():\n",
        "    \"\"\"Init function: initialize YOUTUBE service\"\"\"\n",
        "    print(\"Initializing YOUTUBE service...\")\n",
        "\n",
        "    global YOUTUBE\n",
        "    YOUTUBE = discovery.build(\n",
        "        YT_API_SERVICE_NAME,\n",
        "        YT_API_VERSION,\n",
        "        developerKey=API_KEY)\n",
        "\n",
        "\n",
        "def init_vertex_ai():\n",
        "    \"\"\"Init function: Initialize VertexAI service\"\"\"\n",
        "    print(\"Initializing VERTEXAI service...\")\n",
        "\n",
        "    credentials, project = google.auth.default()\n",
        "    vertexai.init(\n",
        "        project=project,\n",
        "        location=VERTEX_AI_CLOUD_LOCATION,\n",
        "        credentials=credentials)\n",
        "\n",
        "\n",
        "def get_text_moderation(text):\n",
        "    \"\"\"Get moderation for text via Google Cloud Natural Language API\"\"\"\n",
        "    print(f\"Moderating text: {text} ...\")\n",
        "\n",
        "    try:\n",
        "        client = language.LanguageServiceClient()\n",
        "        document = language.Document(\n",
        "            content=text,\n",
        "            type_=language.Document.Type.PLAIN_TEXT,\n",
        "        )\n",
        "\n",
        "        print(\"Successfully got text moderation !\")\n",
        "        return client.moderate_text(document=document)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not moderate the following text: {text}.\")\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_live_chat_id():\n",
        "    \"\"\"Get YouTube live chat id and check live set up\"\"\"\n",
        "    print(\"Collecting live stream information...\")\n",
        "\n",
        "    # Use YouTube API to get live stream info\n",
        "    video_result = execute_youtube_api_call(\n",
        "        YOUTUBE.videos().list,\n",
        "        part=\"snippet,contentDetails,status,LiveStreamingDetails\",\n",
        "        id=LIVE_STREAM_ID,\n",
        "    )\n",
        "\n",
        "    if not video_result or not video_result[\"items\"]:\n",
        "        raise Exception(\n",
        "            \"Live stream not found. Verify that your LIVE_STREAM_ID is \" +\n",
        "            f\"correct: {LIVE_STREAM_ID}, and its privacy is set to \" +\n",
        "            \"'unlisted'. Stream URL: \" +\n",
        "            \"https://studio.youtube.com/video/{LIVE_STREAM_ID}/livestreaming\"\n",
        "        )\n",
        "\n",
        "    video = video_result[\"items\"][0]\n",
        "\n",
        "    # Verify YouTube Live Stream setup\n",
        "    if video[\"status\"][\"privacyStatus\"] == \"public\":\n",
        "        raise Exception(\n",
        "            \"Your live stream privacy is set to public. For safety measures, \" +\n",
        "            \"you should make sure your live stream privacy is set to \" +\n",
        "            \"'unlisted' before you run this script here: \" +\n",
        "            f\"https://studio.youtube.com/video/{LIVE_STREAM_ID}/livestreaming\"\n",
        "        )\n",
        "\n",
        "    if video[\"status\"][\"madeForKids\"]:\n",
        "        raise Exception(\n",
        "            \"Your live stream is flagged as 'Made for kids'.\" +\n",
        "            \"Please, set your live stream as 'Not Made For kids' in the \" +\n",
        "            \"Live Control Room: \"\n",
        "            f\"https://studio.youtube.com/video/{LIVE_STREAM_ID}/livestreaming\"\n",
        "        )\n",
        "\n",
        "    live_chat_id = video[\"liveStreamingDetails\"][\"activeLiveChatId\"]\n",
        "\n",
        "    if not live_chat_id:\n",
        "        raise Exception(\n",
        "            \"No live chat found for your stream. Make sure live chat is \" +\n",
        "            \"enabled for your stream here: \" +\n",
        "            f\"https://studio.youtube.com/video/{LIVE_STREAM_ID}/livestreaming\"\n",
        "        )\n",
        "\n",
        "    print(\"Live stream correctly set up - live chat id fetched successfully !\")\n",
        "\n",
        "    # Return live chat id\n",
        "    return live_chat_id\n",
        "\n",
        "\n",
        "def get_live_stream_last_chat_messages():\n",
        "    \"\"\"Get the last chat messages of YouTube live stream\"\"\"\n",
        "    print(f\"Collecting last live chat messages...\")\n",
        "\n",
        "    global LIVE_CHAT_PAGE_TOKEN\n",
        "\n",
        "    shouldFetch = True  # Fetch until we get last chat messages\n",
        "    last_chat_messages = [FALLBACK_LIVE_CHAT_MESSAGE]\n",
        "\n",
        "    while shouldFetch:\n",
        "        # Get chat messages via YouTube API\n",
        "        live_chat_messages_result = execute_youtube_api_call(\n",
        "            YOUTUBE.liveChatMessages().list,\n",
        "            liveChatId=LIVE_CHAT_ID,\n",
        "            part=\"snippet,authorDetails\",\n",
        "            maxResults=2000,\n",
        "            pageToken=LIVE_CHAT_PAGE_TOKEN,\n",
        "        )\n",
        "\n",
        "        # Based on API result, continue fetching or return last chat message\n",
        "        if (not live_chat_messages_result\n",
        "                or not live_chat_messages_result[\"items\"]):\n",
        "            shouldFetch = False\n",
        "\n",
        "        elif (len(live_chat_messages_result[\"items\"]) == 2000\n",
        "                and live_chat_messages_result[\"nextPageToken\"]):\n",
        "            LIVE_CHAT_PAGE_TOKEN = live_chat_messages_result[\"nextPageToken\"]\n",
        "\n",
        "        else:\n",
        "            shouldFetch = False\n",
        "            last_chat_messages = [\n",
        "                {\n",
        "                    \"messageAuthor\": m[\"authorDetails\"][\"displayName\"],\n",
        "                    \"messageText\": m[\"snippet\"][\"displayMessage\"],\n",
        "                }\n",
        "                for m in reversed(live_chat_messages_result[\"items\"][-15:])\n",
        "            ]\n",
        "\n",
        "    return last_chat_messages\n",
        "\n",
        "\n",
        "def get_most_appropriate_chat_message(live_stream_last_chat_messages):\n",
        "    \"\"\"Get the most appropriate chat message from a list of chat messages\"\"\"\n",
        "    print(f\"Selecting most appropriate live chat message ...\")\n",
        "\n",
        "    for m in live_stream_last_chat_messages:\n",
        "        moderation = get_text_moderation(\n",
        "            f\"{m['messageAuthor']} says: {m['messageText']}\"\n",
        "        )\n",
        "\n",
        "        if moderation:\n",
        "            max_moderation_confidence_score = max(\n",
        "                [mc.confidence for mc in moderation.moderation_categories]\n",
        "            )\n",
        "\n",
        "            if max_moderation_confidence_score < 0.8:\n",
        "                return m\n",
        "\n",
        "    print(\"No appropriate message found. Using fallback chat message\")\n",
        "\n",
        "    return FALLBACK_LIVE_CHAT_MESSAGE\n",
        "\n",
        "\n",
        "def generate_image_from_chat_message(chat_message):\n",
        "    \"\"\"Generate AI image from a chat message using VertexAI\"\"\"\n",
        "    print(\n",
        "        \"Generating image from live chat message: \" +\n",
        "        f\"'{chat_message['messageText']}' ...\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Generate GEN AI image with VertexAI from chat message\n",
        "        model = ImageGenerationModel.from_pretrained(\"imagegeneration@005\")\n",
        "        gen_ai_image = model.generate_images(\n",
        "            prompt=chat_message[\"messageText\"], number_of_images=1\n",
        "        )[0]\n",
        "        gen_ai_image.save(\n",
        "            location=TEMP_IMAGE_PATH,\n",
        "            include_generation_parameters=True)\n",
        "\n",
        "        # Resize image\n",
        "        temp_image = Image.open(TEMP_IMAGE_PATH)\n",
        "        temp_image.thumbnail((IMAGE_SIZE, IMAGE_SIZE))\n",
        "        temp_image.save(TEMP_IMAGE_PATH)\n",
        "\n",
        "        # Insert chat author and text in generated image\n",
        "        image = Image.open(TEMP_IMAGE_PATH)\n",
        "        image.thumbnail((IMAGE_SIZE, IMAGE_SIZE))\n",
        "        font = ImageFont.truetype(font=\"LiberationMono-Regular.ttf\", size=50)\n",
        "        avg_char_width = sum(\n",
        "            font.getbbox(char)[2] for char in ascii_letters\n",
        "        ) / len(ascii_letters)\n",
        "        max_char_count = int(image.size[0] * 0.618 / avg_char_width)\n",
        "        text = textwrap.fill(\n",
        "            text=truncate_string(\n",
        "                f\"From: {chat_message['messageAuthor']} - \" +\n",
        "                f\"{chat_message['messageText']}\",\n",
        "                250,\n",
        "            ),\n",
        "            width=max_char_count,\n",
        "        )\n",
        "\n",
        "        draw = ImageDraw.Draw(im=image)\n",
        "        draw.text(\n",
        "            xy=(image.size[0] / 2, image.size[1] / 2),\n",
        "            text=text,\n",
        "            font=font,\n",
        "            fill=\"#000000\",\n",
        "            anchor=\"mm\",\n",
        "        )\n",
        "\n",
        "        # save as temp image and then rename image to IMAGE_PATH\n",
        "        # (directly saving as IMAGE_PATH does not work well with ffmpeg stream)\n",
        "        image.save(TEMP_IMAGE_PATH, optimize=True, quality=90)\n",
        "        os.rename(TEMP_IMAGE_PATH, IMAGE_PATH)\n",
        "\n",
        "        print(\"Image successfully generated !\")\n",
        "    except Exception as e:\n",
        "        print(\n",
        "            \"failed to generate an AI image - reusing old image instead. \" +\n",
        "            \"Error: \",\n",
        "            e)\n",
        "\n",
        "def create_video_animation():\n",
        "    \"\"\"Create an animation to display on top of Gen AI Image\"\"\"\n",
        "    print(\"Creating video animation...\")\n",
        "\n",
        "    # Init Matplotlib plot\n",
        "    px = 1/plt.rcParams['figure.dpi']\n",
        "    fig, ax = plt.subplots(figsize=(IMAGE_SIZE*px, IMAGE_SIZE*px))\n",
        "    fig.subplots_adjust(\n",
        "        left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
        "    fig.patch.set_alpha(0.0)\n",
        "    ax.set_xlim([0, 1080*px])\n",
        "    ax.set_ylim([-180*px, 900*px])\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Create animation\n",
        "    Nx = 50\n",
        "    Nt = 200\n",
        "    x = np.linspace(0, 1080*px, Nx)\n",
        "    t = np.linspace(1, 25, Nt)\n",
        "    X, T = np.meshgrid(x, t)\n",
        "\n",
        "    S = -np.abs(np.linspace(-1, 1, Nt)) + 1\n",
        "    F1 = 0.2*np.multiply(np.cos(T - X), S[:, None])\n",
        "    F2 = 0.1*np.multiply(np.sin(2*T)*np.cos(X), S[:, None])\n",
        "\n",
        "    frame_number = len(t)-1\n",
        "    C = colormaps['coolwarm'](\n",
        "        np.r_[:frame_number:2, frame_number:0:-2]/frame_number)\n",
        "\n",
        "    fill = ax.fill_between(x, F1[0, :], F2[0, :])\n",
        "\n",
        "    def animate(i):\n",
        "        path = fill.get_paths()[0]\n",
        "        verts = path.vertices\n",
        "        verts[1:Nx+1, 1] = F1[i, :]\n",
        "        verts[Nx+2:-1, 1] = F2[i, :][::-1]\n",
        "        fill.set_color(C[i, :])\n",
        "\n",
        "    anim = FuncAnimation(\n",
        "        fig,\n",
        "        animate,\n",
        "        interval=ANIMATION_TIME_SECONDS * 1000 / frame_number,\n",
        "        frames=frame_number)\n",
        "\n",
        "    # Save animation as temporary and clear figure and plot\n",
        "    anim.save(\n",
        "        TEMP_ANIMATION_PATH,\n",
        "        codec=\"png\",\n",
        "        savefig_kwargs={\"transparent\": True, \"facecolor\": \"none\"},\n",
        "    )\n",
        "    fig.clear()\n",
        "    plt.close()\n",
        "\n",
        "    # Add silent audio to animation video\n",
        "    video_input = ffmpeg.input(TEMP_ANIMATION_PATH)\n",
        "    audio_input = ffmpeg.input(\"anullsrc\", format=\"lavfi\")\n",
        "\n",
        "    ffmpeg.output(\n",
        "        video_input,\n",
        "        audio_input,\n",
        "        ANIMATION_PATH,\n",
        "        vcodec=\"copy\",\n",
        "        acodec=\"aac\",\n",
        "        s=f\"{IMAGE_SIZE}x{IMAGE_SIZE}\",\n",
        "        shortest=None\n",
        "    ).global_args(\"-y\").run()\n",
        "\n",
        "    print(\"Video animation successfully created !\")\n",
        "\n",
        "def send_rtmp_image_stream_to_youtube():\n",
        "    \"\"\"Create and sends an RTMP stream to YouTube from AI Generated image\"\"\"\n",
        "    print(f\"Sending live stream to YouTube via RTMP...\")\n",
        "\n",
        "    image_input = None\n",
        "    video_input = None\n",
        "    vcodec = None\n",
        "    preset = None\n",
        "\n",
        "    if (torch.cuda.is_available()):\n",
        "        image_input = ffmpeg.input(\n",
        "            IMAGE_PATH, loop=1, framerate=0.25, f=\"image2\",\n",
        "            hwaccel=\"cuda\", hwaccel_output_format=\"cuda\")\n",
        "        video_input = ffmpeg.input(\n",
        "            ANIMATION_PATH, stream_loop=-1,\n",
        "            hwaccel=\"cuda\", hwaccel_output_format=\"cuda\")\n",
        "        vcodec = \"h264_nvenc\"\n",
        "        preset = \"fast\"\n",
        "    else:\n",
        "        image_input = ffmpeg.input(\n",
        "            IMAGE_PATH, loop=1, framerate=0.25, f=\"image2\")\n",
        "        video_input = ffmpeg.input(\n",
        "            ANIMATION_PATH, stream_loop=-1)\n",
        "        vcodec = \"libx264\"\n",
        "        preset = \"ultrafast\"\n",
        "\n",
        "    (\n",
        "        ffmpeg\n",
        "        .filter(image_input, 'fps', fps=25, round='up')\n",
        "        .overlay(video_input)\n",
        "        .output(\n",
        "            f\"rtmp://a.rtmp.youtube.com/live2/{LIVE_STREAM_KEY}\",\n",
        "            format=\"fifo\",\n",
        "            fifo_format=\"flv\",\n",
        "            map=\"1:a\",\n",
        "            drop_pkts_on_overflow=1,\n",
        "            attempt_recovery=1,\n",
        "            recovery_wait_time=1,\n",
        "            acodec=\"aac\",\n",
        "            vcodec=vcodec,\n",
        "            preset=preset,\n",
        "            r=25,\n",
        "            g=50,\n",
        "            video_bitrate=\"6M\",\n",
        "            minrate=\"5M\",\n",
        "            maxrate=\"7M\",\n",
        "            bufsize=\"12M\",\n",
        "            timeshift=3,\n",
        "            queue_size=6000\n",
        "        ).run()\n",
        "    )\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Main Processes (will be run in parallel)\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def generate_image_process():\n",
        "    \"\"\"Process that continously creates new images based on new chat messages\"\"\"\n",
        "    while True:\n",
        "        start = time.time()\n",
        "        live_stream_last_chat_messages = get_live_stream_last_chat_messages()\n",
        "        chat_message = get_most_appropriate_chat_message(\n",
        "            live_stream_last_chat_messages)\n",
        "        generate_image_from_chat_message(chat_message)\n",
        "        end = time.time()\n",
        "\n",
        "        generate_new_image_sec = end - start\n",
        "        print(f\"Generated new image in: {generate_new_image_sec}s\")\n",
        "\n",
        "        if(generate_new_image_sec < MIN_IMAGE_AI_GEN_REFRESH_SECONDS):\n",
        "            wait_sec = MIN_IMAGE_AI_GEN_REFRESH_SECONDS - generate_new_image_sec\n",
        "            print(f\"Waiting {wait_sec} seconds before generating new image\")\n",
        "            time.sleep(wait_sec)\n",
        "\n",
        "\n",
        "def stream_image_to_youtube_process():\n",
        "    \"\"\"Process that continuously sends an RTMP stream to YT from GEN AI image\"\"\"\n",
        "    send_rtmp_image_stream_to_youtube()"
      ],
      "metadata": {
        "id": "_OGvRQv-4RDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Execute the final script that will generate images from the live chat messages and send them continuously to YouTube:"
      ],
      "metadata": {
        "id": "mwayKBt__ZYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN FUNCTION\n",
        "\n",
        "def main():\n",
        "    global LIVE_CHAT_ID\n",
        "\n",
        "    # Init YoutTube and VertexAI service\n",
        "    init_youtube_api()\n",
        "    init_vertex_ai()\n",
        "\n",
        "    # Get Live Stream details\n",
        "    LIVE_CHAT_ID = get_live_chat_id()\n",
        "\n",
        "    # Create animation and 1st AI image from fallback message\n",
        "    create_video_animation()\n",
        "    generate_image_from_chat_message(FALLBACK_LIVE_CHAT_MESSAGE)\n",
        "\n",
        "    # Run processes to continuously generate images and send them to YouTube\n",
        "    run_in_parallel(stream_image_to_youtube_process, generate_image_process)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "u-XHFOlT_pXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### And that's it !\n",
        "\n",
        "If you go back to YouTube Studio (`https://studio.youtube.com/video/XXXXXXXXXXX/livestreaming` where XXXXXXXXXXX is your live stream ID), you should see images being sent to your live stream. You can stop sending images whenever you please by stopping the script above (click on the \"stop\" icon on the left of the script). If you want, you can decide to go live by clicking on the \"Go Live\" button in the live control room (but please, remember that this script is experimental). Please also monitor the Colab as it may [stop due to inactivity](https://research.google.com/colaboratory/faq.html#idle-timeouts)"
      ],
      "metadata": {
        "id": "kA1zUe6ZqyqG"
      }
    }
  ]
}