{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Copyright 2025 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ],
      "metadata": {
        "id": "zbv4qRo4-tvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BigQuery View creation script to combine v1.0 & v1.1 report versions.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YouTubeLabs/code-samples/blob/main/create_bigquery_views/bigquery_view_creation_example.ipynb)\n",
        "\n",
        "\n",
        "This colab is intended to be used with content owner\n",
        "reports that were transferred into BigQuery using the [BigQuery Data Transfer\n",
        "Service for YouTube Content Owners](https://cloud.google.com/bigquery/docs/youtube-content-owner-transfer). This colab provides an example on how to create a [logical view](https://cloud.google.com/bigquery/docs/views-intro) that combines a new version of a YouTube Report with a previous version. Throughout the notebook we are using the v1.1 `(_a2)` (non music) Shorts Ads Revenue Summary Report and the old v1.0 `(_a1)` report as an example, but it can be used with any report in [this list](https://developers.google.com/youtube/reporting/revision_history#june-24,-2025).\n",
        "\n",
        "<br>\n",
        "\n",
        "This script looks for the earliest date that data in the v1.1 report is available and then combines with data before that date from the v1.0 report to create a logical view with both reports.\n",
        "\n",
        "<br>\n",
        "\n",
        "This example script uses data from the following two non-music Shorts Ads Revenue reports:\n",
        "- `content_owner_shorts_ad_revenue_summary_a1`\n",
        "- `content_owner_shorts_ad_revenue_summary_a2`\n",
        "\n",
        "**You can modify this colab to create logical views for different reports, just ensure that the columns in the query reflect the columns in the reports.**\n",
        "\n",
        "<br>\n",
        "\n",
        "To run this colab you will need the following:\n",
        "\n",
        "1.   An active BigQuery Data Transfer config with [YouTube Content Owner Transfers](https://cloud.google.com/bigquery/docs/youtube-content-owner-transfer) in your Google Cloud Project.\n",
        "2.   Your Google Cloud Project ID. You can find it on [the home page](https://console.cloud.google.com/) of your Google Cloud console.\n",
        "3.   Your dataset ID where the tables from your BigQuery Transfer Jobs are located.\n",
        "4.   Name that you want your new view to have.\n"
      ],
      "metadata": {
        "id": "BwHpbIvU-_Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\" size=4><strong> Use at your own risk: It is your responsibility to check that the view creation and revenue calculations done with views created in this colab are correct and that all applicable revenue categories are accounted for.</strong></font>\n",
        "\n",
        "<br>\n",
        "\n",
        "Your `REPORT_V0_TABLE` and `REPORT_V1_TABLE` should include the **entire table path,** including the Project ID and the Dataset ID. For example: `my_project.my_dataset.my_report_v0_table`. The script will not re-use the `PROJECT_ID` and `DATASET_ID` parameters that you have defined above, in case your tables or views are in different locations."
      ],
      "metadata": {
        "id": "0Z8C6eNoISwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Google Cloud Project ID\n",
        "PROJECT_ID = \"\" #@param {type:'string', placeholder:'Your Google Cloud Project ID'}\n",
        "\n",
        "# Define your target dataset and the name for the new view.\n",
        "DATASET_ID = \"\" #@param {type:'string', placeholder:'Your Dataset ID'}\n",
        "\n",
        "# Table Name for your Shorts Ads Revenue Summary v1.0 (_a1) table.\n",
        "# Should be a partitioned table in PROJECT_ID.DATASET_NAME.TABLE_NAME format.\n",
        "REPORT_V0_TABLE = \"\" #@param {type:'string', placeholder:'Your Report v1.0 (or _a1) table.'}\n",
        "\n",
        "# Table Name for your Shorts Ads Revenue Summary v1.1 (_a2) table.\n",
        "# Should be a partitioned table in PROJECT_ID.DATASET_NAME.TABLE_NAME format.\n",
        "REPORT_V1_TABLE = \"\" #@param {type:'string', placeholder:'Your Report v1.1 (or _a2) table.'}\n",
        "\n",
        "# ID of the Content Owner for which you want to calculate revenue.\n",
        "VIEW_NAME = \"\" #@param {type:'string', placeholder:'Your New View Name'}\n",
        "\n",
        "min_date_v1_query = f\"\"\"\n",
        "SELECT MIN(TIMESTAMP(_PARTITIONTIME)) AS min_v1_data_date\n",
        "FROM `{REPORT_V1_TABLE}`\n",
        "WHERE _PARTITIONTIME IS NOT NULL\n",
        "\"\"\"\n",
        "default_switch_date = '2050-12-31'"
      ],
      "metadata": {
        "id": "I7mq_M7UoRjZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your Colab environment for Google Cloud.\n",
        "\n",
        "An OAuth pop-up window should appear for authentication."
      ],
      "metadata": {
        "id": "0vhMP1FqDUwS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbMf0WMJQo56"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "def authenticate_to_cloud():\n",
        "  try:\n",
        "    auth.authenticate_user()\n",
        "    print(\"Successfully authenticated to Google Cloud!\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error authenticating to Google Cloud: {e}\")\n",
        "\n",
        "authenticate_to_cloud()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Libaries and Initialize the BigQuery Client"
      ],
      "metadata": {
        "id": "pqRMD1dpDcZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import BigQuery client library and Pandas\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)"
      ],
      "metadata": {
        "id": "GDaryfHe-LaQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the earliest date partition in your v1.1 report.\n",
        "\n",
        "To know which date range to take from each table to create the view, we must\n",
        "find the earliest date that the v1.1 report became available to avoid double counting between the two tables. This is the newer of the two reports."
      ],
      "metadata": {
        "id": "fbchPi12D0Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_earliest_partition(query_earliest_date):\n",
        "  \"\"\"Find the earliest date that the data in a table was available.\"\"\"\n",
        "  print(f\"Attempting to find the earliest _PARTITIONTIME in: \"\n",
        "        f\"{REPORT_V1_TABLE}\")\n",
        "  try:\n",
        "      # Execute the query and fetch the result\n",
        "      min_v1_date = client.query(min_date_v1_query)\n",
        "      min_v1_date_result = min_v1_date.result().to_dataframe()\n",
        "\n",
        "      if (not min_v1_date_result.empty and\n",
        "         pd.notna(min_v1_date_result['min_v1_data_date'].iloc[0])):\n",
        "          # Convert date object to string 'YYYY-MM-DD' for SQL\n",
        "          switch_date = (min_v1_date_result['min_v1_data_date']\n",
        "                         .iloc[0].strftime('%Y-%m-%d'))\n",
        "          print(f\"Date of earliest data found in {REPORT_V1_TABLE} is\"\n",
        "                f\" {switch_date}\")\n",
        "          return switch_date\n",
        "      else:\n",
        "          # Fallback if V1.1 table is empty or _PARTITIONTIME is null\n",
        "          # A far in the future means V0 will cover all data until V1 gets data.\n",
        "\n",
        "          print(f\"No valid date found in {REPORT_V1_TABLE} table. \"\n",
        "                f\"Using default switch date {default_switch_date} instead.\")\n",
        "          return default_switch_date\n",
        "\n",
        "  except Exception as e:\n",
        "      # Fallback if REPORT_V1_TABLE table doesn't exist or query fails\n",
        "      print(f\"Error querying {REPORT_V1_TABLE} table ({e}). Using default\"\n",
        "            f\" switch date {default_switch_date} instead.\")\n",
        "      return default_switch_date\n",
        "\n",
        "switch_date = find_earliest_partition(query_earliest_date=min_date_v1_query)\n",
        "print(f\"Switching from {REPORT_V0_TABLE} to \\n{REPORT_V1_TABLE} data at\"\n",
        "      f\" _PARTITIONTIME >= {switch_date}\")"
      ],
      "metadata": {
        "id": "LfK-fM0486WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the query to create your desired view, combining both tables.\n",
        "\n",
        "The view query takes all v1.0 data before the new v1.1 table was created, unioning it with all data from the new v1.1 table. This will create a combined logical view with data from both tables.\n",
        "\n",
        "In the logical view, `total_views` from the v1.0 `(_a1)` table are renamed to `engaged_views` in this example.\n",
        "\n",
        "As mentioned above, you can modify this colab to create logical views for different reports, just ensure that the columns in the query below also reflect the columns in the available columns in the reports.\n",
        "\n",
        "Then, we have a small query to show 5 rows from the view for you to check if the view was successfully created.\n"
      ],
      "metadata": {
        "id": "ercvOYyVEOOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "view_creation_query = f\"\"\"\n",
        "  CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.{VIEW_NAME}` AS\n",
        "  WITH\n",
        "    ShortsRevenueV0 AS (\n",
        "      SELECT\n",
        "        adjustment_type_,\n",
        "        video_id,\n",
        "        video_title,\n",
        "        video_duration_sec,\n",
        "        category,\n",
        "        channel_id,\n",
        "        uploader,\n",
        "        content_type,\n",
        "        policy,\n",
        "        total_views AS engaged_views,\n",
        "        net_partner_revenue_post_revshare,\n",
        "        DATE(_PARTITIONTIME) AS _DATA_DATE\n",
        "      FROM `{REPORT_V0_TABLE}`\n",
        "      -- V0 data BEFORE the switch date\n",
        "      WHERE TIMESTAMP(_PARTITIONTIME) < '{switch_date}'\n",
        "    ),\n",
        "    ShortsRevenueV1 AS (\n",
        "      SELECT\n",
        "        adjustment_type_,\n",
        "        video_id,\n",
        "        video_title,\n",
        "        video_duration_sec,\n",
        "        category,\n",
        "        channel_id,\n",
        "        uploader,\n",
        "        content_type,\n",
        "        policy,\n",
        "        engaged_views,\n",
        "        net_partner_revenue_post_revshare,\n",
        "        DATE(_PARTITIONTIME) AS _DATA_DATE\n",
        "      FROM `{REPORT_V1_TABLE}`\n",
        "      -- V1 data ON OR AFTER the switch date\n",
        "      WHERE TIMESTAMP(_PARTITIONTIME) >= '{switch_date}'\n",
        "    )\n",
        "  SELECT\n",
        "    *\n",
        "  FROM ShortsRevenueV0\n",
        "  UNION ALL\n",
        "  SELECT\n",
        "    *\n",
        "  FROM ShortsRevenueV1;\n",
        "\"\"\"\n",
        "\n",
        "top_view_results_query = f\"\"\"\n",
        "  SELECT *\n",
        "  FROM `{PROJECT_ID}.{DATASET_ID}.{VIEW_NAME}`\n",
        "  LIMIT 5\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WcpElFxi9eFj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the BigQuery View\n",
        "\n",
        "Function that creates the BigQuery view using the `view_creation_query` above.\n",
        "If this function has run successfully, then you should also see this view available in your BigQuery Studio within the dataset that you've defined above.\n",
        "\n",
        "Depending on how much data you have in the tables that you have combined, it might take some time for the query to complete."
      ],
      "metadata": {
        "id": "gXx_e4hwEoEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bigquery_view(view_creation_query):\n",
        "  \"\"\"Create a view in BigQuery using the view creation query.\"\"\"\n",
        "  print(f\"Now attempting to create or replace view: \"\n",
        "      f\"{PROJECT_ID}.{DATASET_ID}.{VIEW_NAME}\")\n",
        "  try:\n",
        "      # Run the query to create the view.\n",
        "      query_job = client.query(view_creation_query)\n",
        "\n",
        "      # Wait for query to finish running.\n",
        "      query_job.result()\n",
        "\n",
        "      print(f\"View '{VIEW_NAME}' successfully created/updated in dataset\"\n",
        "            f\"'{DATASET_ID}'.\")\n",
        "      print(\"You can verify its existence and data in the BigQuery UI.\")\n",
        "  except Exception as e:\n",
        "      return (f\"Error creating view: {e}\")\n",
        "\n",
        "create_bigquery_view(view_creation_query=view_creation_query)"
      ],
      "metadata": {
        "id": "YDmYhLib9rSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional] Query the View to See That It Was Created Successfully\n",
        "\n",
        "The function below will run a query to display 5 rows of data from the view that has been created above. It will display the output below the code in a data table."
      ],
      "metadata": {
        "id": "kZNgif9cHyCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_view_results(query_string):\n",
        "  \"\"\"Run a sample query to display results from a view.\"\"\"\n",
        "  print(f\"Querying the new view to see some sample data using: {query_string}.\")\n",
        "\n",
        "  try:\n",
        "      # Run the query to create the view.\n",
        "      query_job = client.query(query_string)\n",
        "\n",
        "      # Convert the query results to a Pandas DataFrame.\n",
        "      view_dataframe = query_job.to_dataframe()\n",
        "\n",
        "      print(\"Successfully fetched the data from your view, displaying the \"\n",
        "      \"first 5 rows below:\")\n",
        "\n",
        "      # Display 5 rows of the view.\n",
        "      return display(view_dataframe.head(5))\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"An Error occured querying data using the BigQuery client: {e}\")\n",
        "      return (\"Please check your project ID, dataset ID, view name, \"\n",
        "             \"and/or IAM permissions.\")\n",
        "\n",
        "query_view_results(query_string=top_view_results_query)"
      ],
      "metadata": {
        "id": "q2Yif1A07oM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}