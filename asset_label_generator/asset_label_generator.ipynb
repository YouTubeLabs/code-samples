{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ],
      "metadata": {
        "id": "MkIR2ozDnOAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YouTube Tech Services Asset Label Generator\n",
        "\n",
        "The idea is to order your asset catalog. [Asset labels](https://support.google.com/youtube/answer/6063635?hl=en) are the perfect tool to organize your YouTube assets. They allow you to easily search and update a group of assets. Furthermore, they are included in many reports and allow you to analyze the performance of these asset groups. The asset labels generated by this script are the channel name of the uploader channel of the partner uploaded video of the asset and an optional additional label based on the channel.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "\n",
        "*   Google Drive\n",
        "*   Google Cloud project with [YouTube Reporting API](https://console.cloud.google.com/apis/library/youtubereporting.googleapis.com?), [YouTube Content ID API](https://console.cloud.google.com/apis/library/youtubepartner.googleapis.com), and [Google Sheets API](https://console.cloud.google.com/apis/library/sheets.googleapis.com) enabled\n",
        "*   Google Cloud Project Service Account with Key ([Help Center](https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console))\n",
        "*  YouTube CMS (External Content Owner ID)\n",
        "*  The Service Account need access to the CMS with the following rights (minimum): \"Content Delivery\", \"Reporting and Analytics\" and \"Content ID Rights Management\"\n",
        "\n",
        "This script will:\n",
        "\n",
        "\n",
        "*   Download two reports: content_owner_active_claims_a1 and content_owner_video_metadata_a3\n",
        "*   Combine these reports so that video, channel and asset informations are available\n",
        "*   Use the channel name of the uploaded video as additional label for the asset (plus an additional label if configured)\n",
        "*  [Optional] Apply additional mapping based on the channel ID. The Google sheets need the header \"channel_id\" and \"additional_label\" (e.g. if you want to add another label for multiple channels: Channel1 (LabelA), Channel2 (LabelA), Channel3 (LabelB), Channel4 (LabelB))\n",
        "*  [Optional] Upload and process the generated asset labels via API\n",
        "\n",
        "Please note: The generated asset labels are based on the latest version of the content_owner_active_claims_a1 and content_owner_video_metadata_a3. Usually, these reports are generated once per day, and therefore they might not include the latest asset labels. If you run this Colab multiple times based on the same report (e.g., run it multiple times per day), you may generate the same asset labels. The YouTube system can handle this, and it should not result in any issues.\n",
        "\n"
      ],
      "metadata": {
        "id": "gr0_nU5WoDFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration\n",
        "\n",
        "Please adjust the settings below:\n",
        "\n",
        "*  EXTERNAL_CONTENT_OWNER_ID: ID of your YouTube Content Owner\n",
        "*  DRIVE_FOLDER: folder in your Google Drive to store the downloaded reports and the generated update csv files.\n",
        "*  JSON_FILE: json file with service account credentials, you need to upload this file to the configured Drive folder\n",
        "*  ADDITIONAL_MAPPING: True, if you have an additional mapping based on channel IDs, otherwise False\n",
        "*  ADDITIONAL_MAPPING_SPREADSHEET_ID: ID of the Google Spreadsheet with the additinal mapping (if you open the Spreadsheet this is part of the URL) | the speadsheet needs to columns named 'channel_id' and 'additional_label'\n",
        "*  ADDITIONAL_MAPPING_RANGE: name of the tab in the Google Spreadsheet\n",
        "*  YOUTUBE_CMS_AUTOMATICALLY_UPLOAD: True, if you want to directly upload and process the generated csv file\n",
        "*  YOUTUBE_CMS_UPLOADER_NAME: the name of your YouTube uploader account (usually starts with 'web-yt-')\n",
        "\n"
      ],
      "metadata": {
        "id": "ALDU8bREWWg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7fCtu9ZNpZE"
      },
      "outputs": [],
      "source": [
        "# add the YouTube Content Owner ID\n",
        "EXTERNAL_CONTENT_OWNER_ID = ''  # @param {type:\"string\"}\n",
        "\n",
        "# Google drive folder where the client_secret.json is stored as well as downloaded reports and the generated update csv files\n",
        "DRIVE_FOLDER = 'AssetLabelGenerator'  # @param {type:\"string\"}\n",
        "\n",
        "# Service Account Authentification file\n",
        "# if you download the json file from your Google Cloud project the file has\n",
        "# a different name, therefore you either need to rename the file itself or\n",
        "# adjust the name here you need to upload this file to the configured Cloud folder\n",
        "JSON_FILE = 'client_secret.json'  # @param {type:\"string\"}\n",
        "\n",
        "# indicates if you need an additional mapping depending on the channel ID\n",
        "ADDITIONAL_MAPPING = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# the Google Spreadsheet ID of the additional mapping\n",
        "ADDITIONAL_MAPPING_SPREADSHEET_ID = '' # @param {type:\"string\"}\n",
        "\n",
        "# the Google Spreadsheet tab name of the additional mapping\n",
        "ADDITIONAL_MAPPING_RANGE = ''  # @param {type:\"string\"}\n",
        "\n",
        "# if you want to automatically upload and process the generated csv update\n",
        "YOUTUBE_CMS_AUTOMATICALLY_UPLOAD = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# the name of your YouTube uploader account (usually starts with 'web-yt-')\n",
        "YOUTUBE_CMS_UPLOADER_NAME = ''  # @param {type:\"string\"}\n",
        "\n",
        "# do not change arguments below\n",
        "DRIVE_DIRECTORY_PATH = '/content/drive/My Drive/' + DRIVE_FOLDER + '/'\n",
        "CLAIM_REPORT_TYPE_ID = 'content_owner_active_claims_a1'\n",
        "CLAIM_OUTPUT_FILE = DRIVE_DIRECTORY_PATH + CLAIM_REPORT_TYPE_ID\n",
        "VIDEO_REPORT_TYPE_ID = 'content_owner_video_metadata_a3'\n",
        "VIDEO_OUTPUT_FILE = DRIVE_DIRECTORY_PATH + VIDEO_REPORT_TYPE_ID\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Drive\n",
        "\n",
        "Mount the Google Drive destination and create a specific folder for the script.\n",
        "\n",
        "**NOTE: If this is the first time you run the code, you need to upload your `client_secret.json` oauth file to the Drive folder after is has been created.**"
      ],
      "metadata": {
        "id": "So2RfIZZL4GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# create folder if necessary\n",
        "Path(DRIVE_DIRECTORY_PATH).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "4WOJCdD7bNGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authentication and Google Service Usage\n",
        "\n",
        "List the Google services and methods to access them."
      ],
      "metadata": {
        "id": "3UFtOxU5aR5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient import discovery\n",
        "\n",
        "# Scope, Name, Version for YouTube Data API\n",
        "YOUTUBE_REPORT_API_SERVICE_NAME = 'youtubereporting'\n",
        "YOUTUBE_REPORT_API_VERSION = 'v1'\n",
        "YOUTUBE_REPORT_API_SCOPE = [\n",
        "    'https://www.googleapis.com/auth/yt-analytics-monetary.readonly',\n",
        "    'https://www.googleapis.com/auth/yt-analytics.readonly',\n",
        "]\n",
        "\n",
        "YOUTUBE_PARTNER_API_SERVICE_NAME = 'youtubePartner'\n",
        "YOUTUBE_PARTNER_API_VERSION = 'v1'\n",
        "YOUTUBE_PARTNER_API_SCOPE = [\n",
        "    'https://www.googleapis.com/auth/youtube.force-ssl',\n",
        "    'https://www.googleapis.com/auth/youtubepartner',\n",
        "]\n",
        "\n",
        "GOOGLE_SPREADSHEET_API_SERVICE_NAME = 'sheets'\n",
        "GOOGLE_SPREADSHEET_API_VERSION = 'v4'\n",
        "GOOGLE_SPREADSHEET_API_SCOPE = [\n",
        "    'https://www.googleapis.com/auth/spreadsheets.readonly'\n",
        "]\n",
        "\n",
        "\n",
        "def get_credentials(scopes):\n",
        "  f = open('/content/drive/My Drive/' + DRIVE_FOLDER + '/' + JSON_FILE)\n",
        "  service_account_json = json.load(f)\n",
        "  credentials = service_account.Credentials.from_service_account_info(\n",
        "      service_account_json, scopes=scopes\n",
        "  )\n",
        "  return credentials\n",
        "\n",
        "\n",
        "def get_google_spreadsheet_api_service():\n",
        "  return discovery.build(\n",
        "      GOOGLE_SPREADSHEET_API_SERVICE_NAME,\n",
        "      GOOGLE_SPREADSHEET_API_VERSION,\n",
        "      static_discovery=False,\n",
        "      credentials=get_credentials(GOOGLE_SPREADSHEET_API_SCOPE),\n",
        "  )\n",
        "\n",
        "\n",
        "def get_youtube_partner_api_service():\n",
        "  return discovery.build(\n",
        "      YOUTUBE_PARTNER_API_SERVICE_NAME,\n",
        "      YOUTUBE_PARTNER_API_VERSION,\n",
        "      static_discovery=False,\n",
        "      credentials=get_credentials(YOUTUBE_PARTNER_API_SCOPE),\n",
        "  )\n",
        "\n",
        "\n",
        "def get_youtube_report_api_service():\n",
        "  return discovery.build(\n",
        "      YOUTUBE_REPORT_API_SERVICE_NAME,\n",
        "      YOUTUBE_REPORT_API_VERSION,\n",
        "      static_discovery=False,\n",
        "      credentials=get_credentials(YOUTUBE_REPORT_API_SCOPE),\n",
        "  )\n"
      ],
      "metadata": {
        "id": "Pw_wh8rraC0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Reports\n",
        "\n",
        "The authentication happens at the YouTube Content Owner level; therefore, the EXTERNAL_CONTENT_OWNER_ID needs to be configured (above). The script downloads the [content_owner_active_claims_a1](https://developers.google.com/youtube/reporting/v1/reports/system_managed/claims) report and the [content_owner_video_metadata_a3](https://developers.google.com/youtube/reporting/v1/reports/system_managed/videos).  The reports are stored in the configured Google Drive folder."
      ],
      "metadata": {
        "id": "KXbenLg_b4N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import FileIO\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "\n",
        "def getReportJob(youtube_reporting, report_type_id):\n",
        "  jobListResult = (\n",
        "      youtube_reporting.jobs()\n",
        "      .list(\n",
        "          onBehalfOfContentOwner=EXTERNAL_CONTENT_OWNER_ID,\n",
        "          includeSystemManaged=True,\n",
        "      )\n",
        "      .execute()\n",
        "  )\n",
        "  jobList = jobListResult['jobs']\n",
        "  for job in jobList:\n",
        "    if job['reportTypeId'] == report_type_id:\n",
        "      return job\n",
        "  return None\n",
        "\n",
        "\n",
        "def getReportByJobId(youtube_reporting, id):\n",
        "  reportListResult = (\n",
        "      youtube_reporting.jobs()\n",
        "      .reports()\n",
        "      .list(onBehalfOfContentOwner=EXTERNAL_CONTENT_OWNER_ID, jobId=id)\n",
        "      .execute()\n",
        "  )\n",
        "  reportList = reportListResult['reports']\n",
        "  if reportList.count == 0:\n",
        "    print('No reports available')\n",
        "    return None\n",
        "  return reportList[0]\n",
        "\n",
        "\n",
        "def downloadReport(youtube_reporting, downloadUrl, output_path):\n",
        "  request = youtube_reporting.media().download(resourceName=' ')\n",
        "  request.uri = downloadUrl\n",
        "  fh = FileIO(output_path, mode='wb')\n",
        "  # Stream/download the report in a single request.\n",
        "  downloader = MediaIoBaseDownload(fh, request, chunksize=-1)\n",
        "\n",
        "  done = False\n",
        "  while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    if status:\n",
        "      print('Download %d%%.' % int(status.progress() * 100))\n",
        "  print('Download Complete!')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  youtube_reporting = get_youtube_report_api_service()\n",
        "  # Retrieve the reporting jobs for claim report\n",
        "  reportJob = getReportJob(youtube_reporting, CLAIM_REPORT_TYPE_ID)\n",
        "  print(reportJob)\n",
        "  # Retrieve last Report for claim report\n",
        "  report = getReportByJobId(youtube_reporting, reportJob['id'])\n",
        "  print(report)\n",
        "  # Download the claim report\n",
        "  downloadReport(youtube_reporting, report['downloadUrl'], CLAIM_OUTPUT_FILE)\n",
        "\n",
        "  # Retrieve the reporting jobs for claim report\n",
        "  reportJob = getReportJob(youtube_reporting, VIDEO_REPORT_TYPE_ID)\n",
        "  print(reportJob)\n",
        "  # Retrieve last Report for claim report\n",
        "  report = getReportByJobId(youtube_reporting, reportJob['id'])\n",
        "  print(report)\n",
        "  # Download the claim report\n",
        "  downloadReport(youtube_reporting, report['downloadUrl'], VIDEO_OUTPUT_FILE)\n"
      ],
      "metadata": {
        "id": "FQ2hTNOqOJMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Mapping\n",
        "\n",
        "If you have an additional mapping configured, the script accesses the Google spreadsheet and converts the data into a Pandas data frame."
      ],
      "metadata": {
        "id": "shS6q4wocklM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "if ADDITIONAL_MAPPING:\n",
        "  service = get_google_spreadsheet_api_service()\n",
        "\n",
        "  worksheet = (\n",
        "      service.spreadsheets()\n",
        "      .values()\n",
        "      .get(\n",
        "          spreadsheetId=ADDITIONAL_MAPPING_SPREADSHEET_ID,\n",
        "          range=ADDITIONAL_MAPPING_RANGE,\n",
        "      )\n",
        "      .execute()\n",
        "  )\n",
        "\n",
        "  values = worksheet.get('values', [])\n",
        "  additional_mapping = pd.DataFrame(values[1:], columns=values[0])\n",
        "\n",
        "else:\n",
        "  print('No additional Mapping enabled.')\n"
      ],
      "metadata": {
        "id": "0VO6nzr9GgFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the update csv file to label assets\n",
        "\n",
        "The script reads the two downloaded reports and converts them into a Pandas data frame. Then in join the two reports based on the video ID's. This combined report contains claim_id, video_id, custom_id, claim_origin, asset_id, asset_labels, channel_id and channel_display_name.\n",
        "\n",
        "The scripts remove all entries where the channel is unknown (channel_display_name is empty) or where the asset already has an asset label with the name of the channel.\n",
        "\n",
        "Finally, the script generated an asset update csv file to label all remaining assets and stores that file in the configured Google Drive folder."
      ],
      "metadata": {
        "id": "fhgySZHveBfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def already_labeled_condition(row):\n",
        "  # no asset label\n",
        "  if pd.isna(row['asset_labels']):\n",
        "    return False\n",
        "  # the script was not able to label this asset in a previous run\n",
        "  if row['asset_labels'] in ['NO_CHANNEL_LABEL']:\n",
        "    return True\n",
        "  # check if the channel name is already in the asset labels\n",
        "  return row['channel_display_name'] in row['asset_labels']\n",
        "\n",
        "\n",
        "# read downloaded claim report from Google drive and put it in Pandas dataframe\n",
        "with gzip.open(CLAIM_OUTPUT_FILE) as f:\n",
        "  df_claims = pd.read_csv(\n",
        "      f,\n",
        "      usecols=[\n",
        "          'claim_id',\n",
        "          'video_id',\n",
        "          'custom_id',\n",
        "          'claim_origin',\n",
        "          'asset_id',\n",
        "          'asset_labels',\n",
        "      ],\n",
        "      dtype={\n",
        "          'claim_id': 'string',\n",
        "          'video_id': 'string',\n",
        "          'custom_id': 'string',\n",
        "          'claim_origin': 'string',\n",
        "          'asset_id': 'string',\n",
        "          'asset_labels': 'string',\n",
        "      },\n",
        "  )\n",
        "\n",
        "# replace empty video_id with custom_id (video_id is stored in custom_id for\n",
        "# deleted videos)\n",
        "df_claims.loc[df_claims['video_id'].isnull(), 'video_id'] = df_claims[\n",
        "    'custom_id'\n",
        "]\n",
        "# filter for partner uploaded claims only\n",
        "df_claims_own = df_claims[\n",
        "    df_claims['claim_origin'].isin(\n",
        "        ['PARTNER_API', 'WEB_UPLOAD_BY_OWNER', 'CMS_UPLOAD']\n",
        "    )\n",
        "]\n",
        "\n",
        "# read downloaded video report from Google drive and put it in Pandas dataframe\n",
        "df_video = pd.read_csv(\n",
        "    VIDEO_OUTPUT_FILE,\n",
        "    usecols=['video_id', 'channel_id', 'channel_display_name'],\n",
        "    dtype={\n",
        "        'video_id': 'string',\n",
        "        'channel_id': 'string',\n",
        "        'channel_display_name': 'string',\n",
        "    },\n",
        ")\n",
        "\n",
        "# join claims and videos on video_id\n",
        "df_claim_video = pd.merge(df_claims_own, df_video, on='video_id', how='left')\n",
        "\n",
        "# remove all rows with empty channel name\n",
        "df_claim_video = df_claim_video[\n",
        "    df_claim_video['channel_display_name'].notnull()\n",
        "]\n",
        "# remove character from channel name which are not allowed in asset labels\n",
        "df_claim_video['channel_display_name'] = df_claim_video[\n",
        "    'channel_display_name'\n",
        "].str.replace(r'[,&<>:]+', '', regex=True)\n",
        "\n",
        "df_claim_video['has_label_already'] = df_claim_video.apply(\n",
        "    already_labeled_condition, axis=1\n",
        ")\n",
        "\n",
        "df_claim_video = df_claim_video[~df_claim_video['has_label_already']]\n",
        "\n",
        "if ADDITIONAL_MAPPING:\n",
        "  df_claim_video = pd.merge(\n",
        "      df_claim_video, additional_mapping, on='channel_id', how='left'\n",
        "  )\n",
        "  df_claim_video['additional_label'] = df_claim_video[\n",
        "      'additional_label'\n",
        "  ].replace(np.nan, '')\n",
        "\n",
        "# create a dataframe for the asset update\n",
        "df_asset_update = pd.DataFrame()\n",
        "\n",
        "# append columns to an empty DataFrame\n",
        "df_asset_update['asset_id'] = df_claim_video['asset_id']\n",
        "df_asset_update['custom_id'] = ''\n",
        "df_asset_update['asset_type'] = ''\n",
        "df_asset_update['title'] = ''\n",
        "if ADDITIONAL_MAPPING:\n",
        "  df_asset_update['add_asset_labels'] = (\n",
        "      df_claim_video['channel_display_name']\n",
        "      + '|'\n",
        "      + df_claim_video['additional_label']\n",
        "  )\n",
        "else:\n",
        "  df_asset_update['add_asset_labels'] = df_claim_video['channel_display_name']\n",
        "df_asset_update['ownership'] = ''\n",
        "df_asset_update['enable_content_id'] = ''\n",
        "df_asset_update['reference_filename'] = ''\n",
        "df_asset_update['reference_exclusions'] = ''\n",
        "df_asset_update['match_policy'] = ''\n",
        "df_asset_update['update_all_claims'] = ''\n",
        "df_asset_update['clear_labels'] = ''\n",
        "\n",
        "filepath = Path(DRIVE_DIRECTORY_PATH + 'asset_label_update.csv')\n",
        "df_asset_update = df_asset_update.dropna(subset=['asset_id'])\n",
        "df_asset_update['add_asset_labels'].fillna('NO_CHANNEL_LABEL', inplace=True)\n",
        "df_asset_update = df_asset_update.drop_duplicates(subset=['asset_id'], keep='first')\n",
        "df_asset_update.to_csv(filepath, index=False)\n"
      ],
      "metadata": {
        "id": "urrfVVqRiqrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload and process asset label update\n",
        "\n",
        "If configured, the script uploads the generated update csv file to your YouTube CMS. Please note that the update will be immediately processed. In case the asset update csv contains more than 10k lines, it will be split into chunks of 10k lines. In case the upload fails here (which can happen), we kindly ask you to upload the update csv file manually from your configured Google Drive folder."
      ],
      "metadata": {
        "id": "luZpOLpTf_hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "if YOUTUBE_CMS_AUTOMATICALLY_UPLOAD:\n",
        "  youtube_partner = get_youtube_partner_api_service()\n",
        "  df = pd.read_csv(DRIVE_DIRECTORY_PATH + 'asset_label_update.csv')\n",
        "\n",
        "  # split the update file into chunks of 10k lines\n",
        "  df_chunks = np.array_split(df, len(df) // 10000 + 1)\n",
        "\n",
        "  for i, chunk in enumerate(df_chunks):\n",
        "    filepath = Path(DRIVE_DIRECTORY_PATH + f'asset_label_update_{i}.csv')\n",
        "    chunk.to_csv(filepath, index=False)\n",
        "\n",
        "    with open(\n",
        "        DRIVE_DIRECTORY_PATH + f'asset_label_update_{i}.csv', 'r'\n",
        "    ) as file:\n",
        "      csv_update = file.read()\n",
        "\n",
        "    body = {\n",
        "        'kind': 'youtubePartner#package',\n",
        "        'uploaderName': YOUTUBE_CMS_UPLOADER_NAME,\n",
        "        'name': (\n",
        "            'PTM Colab Label Generator '\n",
        "            + datetime.utcnow().strftime('%F %T.%f')[:-3]\n",
        "        ),\n",
        "        'content': csv_update,\n",
        "    }\n",
        "\n",
        "    result = (\n",
        "        youtube_partner.package()\n",
        "        .insert(onBehalfOfContentOwner=EXTERNAL_CONTENT_OWNER_ID, body=body)\n",
        "        .execute()\n",
        "    )\n",
        "\n",
        "    print('Response: {}'.format(result))\n",
        "\n",
        "  print(\n",
        "      'If there is no error message in the log the packages are uploaded and'\n",
        "      ' will be processed automatically.'\n",
        "  )\n",
        "else:\n",
        "  print(\n",
        "      'Automatic Upload to YouTube is disabled. Either enable it in the config'\n",
        "      ' or upload the files manually from your Drive to the YouTube CMS.'\n",
        "  )\n"
      ],
      "metadata": {
        "id": "g7YOQoPB7PFI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}